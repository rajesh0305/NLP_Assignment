{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:17:37.445087Z","iopub.execute_input":"2025-02-04T12:17:37.445442Z","iopub.status.idle":"2025-02-04T12:17:37.450411Z","shell.execute_reply.started":"2025-02-04T12:17:37.445414Z","shell.execute_reply":"2025-02-04T12:17:37.449740Z"}},"outputs":[],"execution_count":87},{"cell_type":"markdown","source":"# RoadMap to the NLP\n\n1. Python Programming\n2. Text Data Preprocessing\n3. Text Data Converted into the Vector(BOW,Tf-Idf,Uni-gram,Bi-gram,W2Vec,Avg W2Vec ,Transformer,BERT etc)\n4. Word2Vec,Avg Word2Vec\n5. RNN,LSTM-RNN.GRU,GRU-RNN etc\n6. Word-Embedding\n7. Transformer and BERT\n   ","metadata":{}},{"cell_type":"markdown","source":"1. **Tokenization**","metadata":{}},{"cell_type":"code","source":"!pip install nltk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:17:37.457053Z","iopub.execute_input":"2025-02-04T12:17:37.457297Z","iopub.status.idle":"2025-02-04T12:17:40.853479Z","shell.execute_reply.started":"2025-02-04T12:17:37.457272Z","shell.execute_reply":"2025-02-04T12:17:40.852110Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /usr/local/lib/python3.10/site-packages (3.9.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from nltk) (4.67.1)\nRequirement already satisfied: joblib in /usr/local/lib/python3.10/site-packages (from nltk) (1.4.2)\nRequirement already satisfied: click in /usr/local/lib/python3.10/site-packages (from nltk) (8.1.8)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/site-packages (from nltk) (2024.11.6)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":88},{"cell_type":"code","source":"corpus= \"\"\"Hello welcome ,to rajesh kumar NLP tutorial.\nplease do watch the entire course! to become the expert in the nlp.\n\"\"\"\nprint(corpus)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:17:40.854587Z","iopub.execute_input":"2025-02-04T12:17:40.855035Z","iopub.status.idle":"2025-02-04T12:17:40.859473Z","shell.execute_reply.started":"2025-02-04T12:17:40.855007Z","shell.execute_reply":"2025-02-04T12:17:40.858664Z"}},"outputs":[{"name":"stdout","text":"Hello welcome ,to rajesh kumar NLP tutorial.\nplease do watch the entire course! to become the expert in the nlp.\n\n","output_type":"stream"}],"execution_count":89},{"cell_type":"markdown","source":"1.1 **Sentence Tokenization**","metadata":{}},{"cell_type":"code","source":"import nltk\nnltk.download('punkt_tab')\n\nfrom nltk.tokenize import sent_tokenize \n\n# corpus = \"This is a sample text. It contains multiple sentences. NLTK should tokenize them correctly.\"\nprint(sent_tokenize(corpus,language = \"english\"))\n\n#Creating the Documents\ndocuments = sent_tokenize(corpus)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:17:40.860262Z","iopub.execute_input":"2025-02-04T12:17:40.860464Z","iopub.status.idle":"2025-02-04T12:17:40.873597Z","shell.execute_reply.started":"2025-02-04T12:17:40.860442Z","shell.execute_reply":"2025-02-04T12:17:40.872756Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n[nltk_data]   Package punkt_tab is already up-to-date!\n","output_type":"stream"},{"name":"stdout","text":"['Hello welcome ,to rajesh kumar NLP tutorial.', 'please do watch the entire course!', 'to become the expert in the nlp.']\n","output_type":"stream"}],"execution_count":90},{"cell_type":"code","source":"documents","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:17:40.874388Z","iopub.execute_input":"2025-02-04T12:17:40.874697Z","iopub.status.idle":"2025-02-04T12:17:40.885528Z","shell.execute_reply.started":"2025-02-04T12:17:40.874676Z","shell.execute_reply":"2025-02-04T12:17:40.884880Z"}},"outputs":[{"execution_count":91,"output_type":"execute_result","data":{"text/plain":"['Hello welcome ,to rajesh kumar NLP tutorial.',\n 'please do watch the entire course!',\n 'to become the expert in the nlp.']"},"metadata":{}}],"execution_count":91},{"cell_type":"code","source":"print(type(documents))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:17:40.886685Z","iopub.execute_input":"2025-02-04T12:17:40.886999Z","iopub.status.idle":"2025-02-04T12:17:40.895180Z","shell.execute_reply.started":"2025-02-04T12:17:40.886974Z","shell.execute_reply":"2025-02-04T12:17:40.894173Z"}},"outputs":[{"name":"stdout","text":"<class 'list'>\n","output_type":"stream"}],"execution_count":92},{"cell_type":"code","source":"for sentence in documents:\n    print(sentence)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:17:40.895951Z","iopub.execute_input":"2025-02-04T12:17:40.896193Z","iopub.status.idle":"2025-02-04T12:17:40.905390Z","shell.execute_reply.started":"2025-02-04T12:17:40.896170Z","shell.execute_reply":"2025-02-04T12:17:40.904498Z"}},"outputs":[{"name":"stdout","text":"Hello welcome ,to rajesh kumar NLP tutorial.\nplease do watch the entire course!\nto become the expert in the nlp.\n","output_type":"stream"}],"execution_count":93},{"cell_type":"markdown","source":"1.2 **Word Tokenization**\n\n1.2.1 Paragraph-->Words\n\n1.2.2 Sentences-->Words","metadata":{}},{"cell_type":"code","source":"from nltk.tokenize import word_tokenize\n\n# 1.2.1 Paragraph to the word tokenization \nwords = word_tokenize(corpus)\n\n#1.2.2 Sentences to the word tokenization \nwords1 =[]\nfor sen in documents:\n    print(word_tokenize(sen))\n    words1.append(word_tokenize(sen))\n\nprint(\"The list of the word after conversion of the documents into the words\\n\")\nprint(words1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:17:40.906153Z","iopub.execute_input":"2025-02-04T12:17:40.906374Z","iopub.status.idle":"2025-02-04T12:17:40.917601Z","shell.execute_reply.started":"2025-02-04T12:17:40.906352Z","shell.execute_reply":"2025-02-04T12:17:40.916860Z"}},"outputs":[{"name":"stdout","text":"['Hello', 'welcome', ',', 'to', 'rajesh', 'kumar', 'NLP', 'tutorial', '.']\n['please', 'do', 'watch', 'the', 'entire', 'course', '!']\n['to', 'become', 'the', 'expert', 'in', 'the', 'nlp', '.']\nThe list of the word after conversion of the documents into the words\n\n[['Hello', 'welcome', ',', 'to', 'rajesh', 'kumar', 'NLP', 'tutorial', '.'], ['please', 'do', 'watch', 'the', 'entire', 'course', '!'], ['to', 'become', 'the', 'expert', 'in', 'the', 'nlp', '.']]\n","output_type":"stream"}],"execution_count":94},{"cell_type":"code","source":"#Here we are using the word punctuation \nfrom nltk.tokenize import wordpunct_tokenize\n\nwordpunct_tokenize(corpus)\n# text = \"Hello, world! How's everything going?\"\n# tokens = wordpunct_tokenize(text)\n# print(tokens)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:17:40.918468Z","iopub.execute_input":"2025-02-04T12:17:40.918653Z","iopub.status.idle":"2025-02-04T12:17:40.930405Z","shell.execute_reply.started":"2025-02-04T12:17:40.918633Z","shell.execute_reply":"2025-02-04T12:17:40.929750Z"}},"outputs":[{"execution_count":95,"output_type":"execute_result","data":{"text/plain":"['Hello',\n 'welcome',\n ',',\n 'to',\n 'rajesh',\n 'kumar',\n 'NLP',\n 'tutorial',\n '.',\n 'please',\n 'do',\n 'watch',\n 'the',\n 'entire',\n 'course',\n '!',\n 'to',\n 'become',\n 'the',\n 'expert',\n 'in',\n 'the',\n 'nlp',\n '.']"},"metadata":{}}],"execution_count":95},{"cell_type":"code","source":"# here we are using the Treebank word Tokenizer \n#for the corpus to the tokens(words)\nfrom nltk.tokenize import TreebankWordTokenizer\ntokenizer = TreebankWordTokenizer()\ntokenizer.tokenize(corpus)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:17:40.931399Z","iopub.execute_input":"2025-02-04T12:17:40.931800Z","iopub.status.idle":"2025-02-04T12:17:40.944329Z","shell.execute_reply.started":"2025-02-04T12:17:40.931778Z","shell.execute_reply":"2025-02-04T12:17:40.943458Z"}},"outputs":[{"execution_count":96,"output_type":"execute_result","data":{"text/plain":"['Hello',\n 'welcome',\n ',',\n 'to',\n 'rajesh',\n 'kumar',\n 'NLP',\n 'tutorial.',\n 'please',\n 'do',\n 'watch',\n 'the',\n 'entire',\n 'course',\n '!',\n 'to',\n 'become',\n 'the',\n 'expert',\n 'in',\n 'the',\n 'nlp',\n '.']"},"metadata":{}}],"execution_count":96},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
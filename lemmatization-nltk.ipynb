{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[],"dockerImageVersionId":30841,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-04T14:04:17.441852Z","iopub.execute_input":"2025-02-04T14:04:17.442189Z","iopub.status.idle":"2025-02-04T14:04:20.156151Z","shell.execute_reply.started":"2025-02-04T14:04:17.442163Z","shell.execute_reply":"2025-02-04T14:04:20.154430Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install nltk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T14:04:20.157007Z","iopub.execute_input":"2025-02-04T14:04:20.157361Z","iopub.status.idle":"2025-02-04T14:04:25.945274Z","shell.execute_reply.started":"2025-02-04T14:04:20.157334Z","shell.execute_reply":"2025-02-04T14:04:25.943879Z"}},"outputs":[{"name":"stdout","text":"Collecting nltk\n  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.10/site-packages (from nltk) (1.4.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from nltk) (4.67.1)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/site-packages (from nltk) (2024.11.6)\nRequirement already satisfied: click in /usr/local/lib/python3.10/site-packages (from nltk) (8.1.8)\nInstalling collected packages: nltk\nSuccessfully installed nltk-3.9.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Lemmatization:\n\nLemmatization is the process of grouping together the different inflected forms of a word so they can be analyzed as a single item. Lemmatization is similar to stemming but it brings context to the words. So, it links words with similar meanings to one word. \nText preprocessing includes both Stemming as well as lemmatization. Many times, people find these two terms confusing. Some treat these two as the same. Lemmatization is preferred over Stemming because lemmatization does morphological analysis of the words.\n\nTypes Of Lemmatization:\n\n1. WordNet\n2. WordNet (with POS tag)\n3. TextBlob\n4. TextBlob (with POS tag)\n5. spaCy\n6. TreeTagger\n7. Pattern\n8. Gensim\n9. Stanford CoreNLP\n","metadata":{}},{"cell_type":"markdown","source":"1. **Wordnet Lemmatizer**\n\n   =>Lemmatization technique is like stemming. The output we will get after lemmatization is called 'Lemma',which ia not root word rather than root stem,the output of stemming.after Lemmatization ,we we will getting a valid word that means the same things.\n\n   =>NLTK provides WordNetLemmatizer class which is a thin wraper around the wordnet corpus.This class uses morphy() function to wordnet CorpusReader class to find a lemma,","metadata":{}},{"cell_type":"code","source":"import nltk\nnltk.download('wordnet')\nfrom nltk.stem import WordNetLemmatizer\n#creating the wordnetLemmatizer class objects\nlemmatizer = WordNetLemmatizer()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T14:04:25.946128Z","iopub.execute_input":"2025-02-04T14:04:25.946403Z","iopub.status.idle":"2025-02-04T14:04:27.831536Z","shell.execute_reply.started":"2025-02-04T14:04:25.946373Z","shell.execute_reply":"2025-02-04T14:04:27.830469Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /root/nltk_data...\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"'''\n1. word (str) – The input word to lemmatize.\n\n2. pos (str) – The Part Of Speech tag.\nValid options are “n” for nouns, \n                   “v” for verbs, \n                   “a” for adjectives,\n                   “r” for adverbs and \n                   “s” for satellite adjectives.\n\n3. pos – str\n'''\nprint(lemmatizer.lemmatize(\"history\",pos ='s'))\nprint(lemmatizer.lemmatize(\"going\",pos = 'v'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T14:04:27.832654Z","iopub.execute_input":"2025-02-04T14:04:27.833034Z","iopub.status.idle":"2025-02-04T14:04:31.081055Z","shell.execute_reply.started":"2025-02-04T14:04:27.833008Z","shell.execute_reply":"2025-02-04T14:04:31.080035Z"}},"outputs":[{"name":"stdout","text":"history\ngo\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"words = [\"eating\",\"eats\",\"eate\",\"writing\",\"writes\",\n        \"programming\",\"programs\",\"history\",\"finally\",\"finalize\"]\nfor word in words:\n    print(word+\"------>\"+lemmatizer.lemmatize(word,pos = \"v\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T14:04:31.082482Z","iopub.execute_input":"2025-02-04T14:04:31.082746Z","iopub.status.idle":"2025-02-04T14:04:31.087320Z","shell.execute_reply.started":"2025-02-04T14:04:31.082704Z","shell.execute_reply":"2025-02-04T14:04:31.086328Z"}},"outputs":[{"name":"stdout","text":"eating------>eat\neats------>eat\neate------>eate\nwriting------>write\nwrites------>write\nprogramming------>program\nprograms------>program\nhistory------>history\nfinally------>finally\nfinalize------>finalize\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# WORDNET LEMMATIZER (with appropriate pos tags)\n\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nnltk.download('punkt_tab')\nnltk.download('averaged_perceptron_tagger')\nnltk.download('averaged_perceptron_tagger_eng')\nfrom nltk.corpus import wordnet\n\nlemmatizer = WordNetLemmatizer()\n\n# Define function to lemmatize each word with its POS tag\n\n# POS_TAGGER_FUNCTION : TYPE 1\ndef pos_tagger(nltk_tag):\n\tif nltk_tag.startswith('J'):\n\t\treturn wordnet.ADJ\n\telif nltk_tag.startswith('V'):\n\t\treturn wordnet.VERB\n\telif nltk_tag.startswith('N'):\n\t\treturn wordnet.NOUN\n\telif nltk_tag.startswith('R'):\n\t\treturn wordnet.ADV\n\telse:\t\t \n\t\treturn None\n\nsentence = 'the cat is sitting with the bats on the striped mat under many badly flying geese'\n\n# tokenize the sentence and find the POS tag for each token\npos_tagged = nltk.pos_tag(nltk.word_tokenize(sentence)) \n\nprint(pos_tagged)\n#>[('the', 'DT'), ('cat', 'NN'), ('is', 'VBZ'), ('sitting', 'VBG'), ('with', 'IN'), \n# ('the', 'DT'), ('bats', 'NNS'), ('on', 'IN'), ('the', 'DT'), ('striped', 'JJ'), \n# ('mat', 'NN'), ('under', 'IN'), ('many', 'JJ'), ('flying', 'VBG'), ('geese', 'JJ')]\n\n# As you may have noticed, the above pos tags are a little confusing.\n\n# we use our own pos_tagger function to make things simpler to understand.\nwordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tagged))\nprint(wordnet_tagged)\n#>[('the', None), ('cat', 'n'), ('is', 'v'), ('sitting', 'v'), ('with', None), \n# ('the', None), ('bats', 'n'), ('on', None), ('the', None), ('striped', 'a'), \n# ('mat', 'n'), ('under', None), ('many', 'a'), ('flying', 'v'), ('geese', 'a')]\n\nlemmatized_sentence = []\nfor word, tag in wordnet_tagged:\n\tif tag is None:\n\t\t# if there is no available tag, append the token as is\n\t\tlemmatized_sentence.append(word)\n\telse:\t \n\t\t# else use the tag to lemmatize the token\n\t\tlemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\nlemmatized_sentence = \" \".join(lemmatized_sentence)\n\nprint(lemmatized_sentence)\n#> the cat can be sit with the bat on the striped mat under many fly geese\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T14:06:09.688964Z","iopub.execute_input":"2025-02-04T14:06:09.689331Z","iopub.status.idle":"2025-02-04T14:06:09.956876Z","shell.execute_reply.started":"2025-02-04T14:06:09.689294Z","shell.execute_reply":"2025-02-04T14:06:09.955761Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n[nltk_data]   Package punkt_tab is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /root/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n[nltk_data]     /root/nltk_data...\n[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n","output_type":"stream"},{"name":"stdout","text":"[('the', 'DT'), ('cat', 'NN'), ('is', 'VBZ'), ('sitting', 'VBG'), ('with', 'IN'), ('the', 'DT'), ('bats', 'NNS'), ('on', 'IN'), ('the', 'DT'), ('striped', 'JJ'), ('mat', 'NN'), ('under', 'IN'), ('many', 'JJ'), ('badly', 'RB'), ('flying', 'VBG'), ('geese', 'JJ')]\n[('the', None), ('cat', 'n'), ('is', 'v'), ('sitting', 'v'), ('with', None), ('the', None), ('bats', 'n'), ('on', None), ('the', None), ('striped', 'a'), ('mat', 'n'), ('under', None), ('many', 'a'), ('badly', 'r'), ('flying', 'v'), ('geese', 'a')]\nthe cat be sit with the bat on the striped mat under many badly fly geese\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
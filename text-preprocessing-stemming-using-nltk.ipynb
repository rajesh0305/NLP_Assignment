{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-04T13:12:26.536181Z","iopub.execute_input":"2025-02-04T13:12:26.536526Z","iopub.status.idle":"2025-02-04T13:12:26.540962Z","shell.execute_reply.started":"2025-02-04T13:12:26.536500Z","shell.execute_reply":"2025-02-04T13:12:26.540272Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"!pip install nltk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T13:12:26.544677Z","iopub.execute_input":"2025-02-04T13:12:26.544919Z","iopub.status.idle":"2025-02-04T13:12:29.855766Z","shell.execute_reply.started":"2025-02-04T13:12:26.544891Z","shell.execute_reply":"2025-02-04T13:12:29.854552Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /usr/local/lib/python3.10/site-packages (3.9.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from nltk) (4.67.1)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/site-packages (from nltk) (2024.11.6)\nRequirement already satisfied: click in /usr/local/lib/python3.10/site-packages (from nltk) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.10/site-packages (from nltk) (1.4.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"1. **Stemming**\n\n=> Stemming is a method in text processing that eliminates prefixes and suffixes from words, transforming them into their fundamental or root form, The main objective of stemming is to streamline and standardize words, enhancing the effectiveness of the natural language processing tasks.\n\n=> Simplifying words to their most basic form is called stemming, and it is made easier by stemmers or stemming algorithms. For example, “chocolates” becomes “chocolate” and “retrieval” becomes “retrieve.” This is crucial for pipelines for natural language processing, which use tokenized words that are acquired from the first stage of dissecting a document into its constituent words.\n\n=>Stemming in natural language processing reduces words to their base or root form, aiding in text normalization for easier processing. This technique is crucial in tasks like text classification, information retrieval, and text summarization. While beneficial, stemming has drawbacks, including potential impacts on text readability and occasional inaccuracies in determining the correct root form of a word.","metadata":{}},{"cell_type":"code","source":"words =[\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\",\"history\",\"finally\",\"finalize\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T13:12:29.856596Z","iopub.execute_input":"2025-02-04T13:12:29.856850Z","iopub.status.idle":"2025-02-04T13:12:29.861105Z","shell.execute_reply.started":"2025-02-04T13:12:29.856821Z","shell.execute_reply":"2025-02-04T13:12:29.860361Z"}},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":"1.1 **Porter Stemmer**","metadata":{}},{"cell_type":"code","source":"from nltk.stem import PorterStemmer\nstemming= PorterStemmer()#here we are creating the porter stemmer\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T13:12:29.862274Z","iopub.execute_input":"2025-02-04T13:12:29.862527Z","iopub.status.idle":"2025-02-04T13:12:29.874813Z","shell.execute_reply.started":"2025-02-04T13:12:29.862506Z","shell.execute_reply":"2025-02-04T13:12:29.873610Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"for word in words:\n    print(word+\"--->\"+stemming.stem(word))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T13:12:29.875423Z","iopub.execute_input":"2025-02-04T13:12:29.875621Z","iopub.status.idle":"2025-02-04T13:12:29.884830Z","shell.execute_reply.started":"2025-02-04T13:12:29.875600Z","shell.execute_reply":"2025-02-04T13:12:29.883629Z"}},"outputs":[{"name":"stdout","text":"eating--->eat\neats--->eat\neaten--->eaten\nwriting--->write\nwrites--->write\nprogramming--->program\nprograms--->program\nhistory--->histori\nfinally--->final\nfinalize--->final\n","output_type":"stream"}],"execution_count":37},{"cell_type":"markdown","source":"**Observation:** Here we can see that the words \"history\"-->\"histori\"==>this is totally changes the meaning of the word history.This is the limitation of the PorterStemmer.","metadata":{}},{"cell_type":"code","source":"print(stemming.stem('congratulations'))\nprint(stemming.stem('sitting'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T13:12:29.885561Z","iopub.execute_input":"2025-02-04T13:12:29.885783Z","iopub.status.idle":"2025-02-04T13:12:29.894255Z","shell.execute_reply.started":"2025-02-04T13:12:29.885762Z","shell.execute_reply":"2025-02-04T13:12:29.893562Z"}},"outputs":[{"name":"stdout","text":"congratul\nsit\n","output_type":"stream"}],"execution_count":38},{"cell_type":"markdown","source":"2. **RegexpStemmer class**(Regular Expression Stemmer)\n\n   2.1 A stemmer that uses regular expressions to identify morphological affixes. Any substrings that match the regular expressions will be removed.\n\n   2.2 Parameters:\t\n\n       2.2.1  regexp (str or regexp) – The regular expression that should be used to identify morphological affixes.\n       2.2.2 min (int) – The minimum length of string to stem\n   \n2.3 NLTK has RegexpStemmer class with the help of which we can easily implements regular expression stemmer algorithms.It basically takes a single regular expression and removes any prefix or suffix that matches the expression.","metadata":{}},{"cell_type":"code","source":"from nltk.stem import RegexpStemmer\nreg_Stemmer= RegexpStemmer('ing$|s$|ize$|able$|e$',min = 4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T13:12:29.895185Z","iopub.execute_input":"2025-02-04T13:12:29.895396Z","iopub.status.idle":"2025-02-04T13:12:29.903013Z","shell.execute_reply.started":"2025-02-04T13:12:29.895376Z","shell.execute_reply":"2025-02-04T13:12:29.902359Z"}},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":"**Note**: Dollor($) position decide the which part of the words going for the stemming.\n1. if(Dollar is on right side ){\n\n   remove the suffix part of the word\n   \n   }else if(Dollar is on left side ){\n\n    remove the suffix part\n\n\n   }else{\n           remove suffix and prefix both part\n   }\n   ","metadata":{}},{"cell_type":"code","source":"for word in words:\n    print(word+\"---->\"+reg_Stemmer.stem(word))\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T13:12:29.903942Z","iopub.execute_input":"2025-02-04T13:12:29.904127Z","iopub.status.idle":"2025-02-04T13:12:29.912434Z","shell.execute_reply.started":"2025-02-04T13:12:29.904108Z","shell.execute_reply":"2025-02-04T13:12:29.911587Z"}},"outputs":[{"name":"stdout","text":"eating---->eat\neats---->eat\neaten---->eaten\nwriting---->writ\nwrites---->write\nprogramming---->programm\nprograms---->program\nhistory---->history\nfinally---->finally\nfinalize---->final\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"3. **Snowball Stemmer**\n   \n   It is a stemming algorithm which is also known as the Porter2 stemming algorithm as it is a better version of the Porter Stemmer since some issues of it were fixed in this stemmer.","metadata":{}},{"cell_type":"code","source":"from nltk.stem import SnowballStemmer\n\n#now we are creating the SnowballStemmer object\nsnowball_stemmer = SnowballStemmer(language = \"english\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T13:12:29.913348Z","iopub.execute_input":"2025-02-04T13:12:29.913612Z","iopub.status.idle":"2025-02-04T13:12:29.921626Z","shell.execute_reply.started":"2025-02-04T13:12:29.913591Z","shell.execute_reply":"2025-02-04T13:12:29.920846Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"for word in words:\n    print(word+\"--->\"+snowball_stemmer.stem(word))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T13:12:29.922518Z","iopub.execute_input":"2025-02-04T13:12:29.922919Z","iopub.status.idle":"2025-02-04T13:12:29.931458Z","shell.execute_reply.started":"2025-02-04T13:12:29.922897Z","shell.execute_reply":"2025-02-04T13:12:29.930611Z"}},"outputs":[{"name":"stdout","text":"eating--->eat\neats--->eat\neaten--->eaten\nwriting--->write\nwrites--->write\nprogramming--->program\nprograms--->program\nhistory--->histori\nfinally--->final\nfinalize--->final\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"#still we are getting the same result as we get the porter stemmer result\nstemming.stem('fairly'),stemming.stem('sportingly')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T13:12:29.932564Z","iopub.execute_input":"2025-02-04T13:12:29.932788Z","iopub.status.idle":"2025-02-04T13:12:29.942342Z","shell.execute_reply.started":"2025-02-04T13:12:29.932767Z","shell.execute_reply":"2025-02-04T13:12:29.941359Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"('fairli', 'sportingli')"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"snowball_stemmer.stem('fairly'),snowball_stemmer.stem('sportingly')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T13:12:48.158533Z","iopub.execute_input":"2025-02-04T13:12:48.158857Z","iopub.status.idle":"2025-02-04T13:12:48.163948Z","shell.execute_reply.started":"2025-02-04T13:12:48.158833Z","shell.execute_reply":"2025-02-04T13:12:48.163149Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"('fair', 'sport')"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}